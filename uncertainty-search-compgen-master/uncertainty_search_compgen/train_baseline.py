import sys
import os
import gc

project_root = "/home/wangx36/uncertainty-search-compgen-master/uncertainty-search-compgen-master"
if project_root not in sys.path:
    sys.path.append(project_root)

os.chdir("/home/wangx36/uncertainty-search-compgen-master/uncertainty-search-compgen-master")
sys.path.append("/home/wangx36/.local/lib/python3.11/site-packages")

if __name__ == "__main__":
    __package__ = "uncertainty_search_compgen"

import torch
import torch.nn as nn
import pytorch_lightning as pl
from torch.utils.data import DataLoader
from transformers import T5ForConditionalGeneration, T5Config, AutoConfig
from .train_lm import T5Module
from .dataset import TokenizerPairIterableDataset
from .load_hf_lm import load_hf_tokenizer
from .data import load_smcalflow_cs_simplified
import pathlib
import argparse


def train_baseline_model(
    model_name_or_path="Salesforce/codet5p-220m",
    data_path="/home/wangx36/uncertainty-search-compgen-master/uncertainty-search-compgen-master/text/semparse/smcalflow-cs",
    output_dir="logs_baseline",
    max_steps=10000,
    batch_size=52
):
    """è®­ç»ƒåªæœ‰æ ‡å‡†T5çš„åŸºå‡†æ¨¡å‹ï¼ˆæ²¡æœ‰ATSå¤´ï¼‰"""
    
    print("ğŸ¯ è®­ç»ƒåŸºå‡†æ¨¡å‹ï¼ˆæ²¡æœ‰adaptive temperature headï¼‰")
    print(f"   æ¨¡å‹: {model_name_or_path}")
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")
    print(f"   æœ€å¤§æ­¥æ•°: {max_steps}")
    
    # è®¾ç½®éšæœºç§å­
    pl.seed_everything(0)
    
    # åŠ è½½æ•°æ®
    basepath = pathlib.Path(data_path)
    train_pairs, _, val_pairs, _ = load_smcalflow_cs_simplified(basepath)
    tokenizer, _ = load_hf_tokenizer(model_name_or_path)
    
    print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"   è®­ç»ƒæ ·æœ¬: {len(train_pairs)}")
    print(f"   éªŒè¯æ ·æœ¬: {len(val_pairs)}")
    
    # åŠ è½½æ¨¡å‹
    config = AutoConfig.from_pretrained(
        model_name_or_path,
        output_hidden_states=True,
        return_dict=True,
        use_cache=False
    )
    model = T5ForConditionalGeneration.from_pretrained(
        model_name_or_path,
        config=config,
        cache_dir="/tmp/hf"
    )
    
    # åˆ›å»ºåŸºå‡†æ¨¡å‹ï¼ˆtrain_mode="t5"è¡¨ç¤ºä¸ä½¿ç”¨ATSå¤´ï¼‰
    harness = T5Module(
        model, 
        pad_token=tokenizer.pad_token_id,
        hidden_size=model.config.d_model,
        train_mode="t5"  # ğŸ”‘ å…³é”®ï¼šåªè®­ç»ƒæ ‡å‡†T5ï¼Œä¸ä½¿ç”¨ATSå¤´
    )
    
    print("âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼ˆATSå¤´å·²å†»ç»“ï¼‰")
    
    # è®¾ç½®è®­ç»ƒå™¨
    torch.set_float32_matmul_precision("medium")
    
    if torch.cuda.is_available():
        accelerator = "gpu"
        devices = 1
        precision = "bf16-mixed" if torch.cuda.is_bf16_supported() else "16-mixed"
        print("ğŸš€ ä½¿ç”¨GPUè®­ç»ƒ")
    else:
        accelerator = "cpu"
        devices = 1
        precision = "32"
        print("ğŸŒ ä½¿ç”¨CPUè®­ç»ƒ")
    
    trainer = pl.Trainer(
        max_steps=max_steps,
        val_check_interval=500,
        num_sanity_val_steps=1,
        accelerator=accelerator,
        devices=devices,
        precision=precision,
        accumulate_grad_batches=1,
        enable_checkpointing=False,
        default_root_dir=output_dir
    )
    
    # å¼€å§‹è®­ç»ƒ
    print("ğŸƒâ€â™‚ï¸ å¼€å§‹è®­ç»ƒåŸºå‡†æ¨¡å‹...")
    trainer.fit(
        harness,
        DataLoader(
            TokenizerPairIterableDataset(list(train_pairs), tokenizer),
            batch_size=batch_size,
        ),
        DataLoader(
            TokenizerPairIterableDataset(list(val_pairs), tokenizer), 
            batch_size=batch_size
        ),
    )
    
    # ä¿å­˜æ¨¡å‹
    output_path = f"{output_dir}/baseline_t5_model.ckpt"
    torch.save({
        "state_dict": harness.state_dict(),
        "pytorch-lightning_version": "2.2.2"
    }, output_path)
    
    print(f"âœ… åŸºå‡†æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“ æ¨¡å‹ä¿å­˜è‡³: {output_path}")
    
    return trainer, model, harness


def main():
    parser = argparse.ArgumentParser(description="è®­ç»ƒåŸºå‡†T5æ¨¡å‹ï¼ˆä¸ä½¿ç”¨ATSå¤´ï¼‰")
    parser.add_argument("--model_name_or_path", type=str, default="Salesforce/codet5p-220m")
    parser.add_argument("--data_path", type=str, 
                        default="/home/wangx36/uncertainty-search-compgen-master/uncertainty-search-compgen-master/text/semparse/smcalflow-cs")
    parser.add_argument("--output_dir", type=str, default="logs_baseline")
    parser.add_argument("--max_steps", type=int, default=10000, help="è®­ç»ƒæ­¥æ•°")
    parser.add_argument("--batch_size", type=int, default=52)
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    pathlib.Path(args.output_dir).mkdir(exist_ok=True, parents=True)
    
    # å¼€å§‹è®­ç»ƒ
    train_baseline_model(
        model_name_or_path=args.model_name_or_path,
        data_path=args.data_path,
        output_dir=args.output_dir,
        max_steps=args.max_steps,
        batch_size=args.batch_size
    )


if __name__ == "__main__":
    main() 